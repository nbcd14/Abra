{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of using the Abra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from transformations import *\n",
    "from selection import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example uses the naics5811 [dataset](http://www.nber.org/nberces/). A description of the columns is [here](http://www.nber.org/nberces/nberces5811/nberces_5811_summary_stats.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('~/Downloads/naics5811.csv')\n",
    "data = data.drop(['naics'], axis=1)\n",
    "train, test = train_test_split(data,test_size=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_standard_transforms_for_dataset creates a list of dicts describing standard transformations (e.g. imputations, caps, floors, onehot encoding, ihs transforms) and their parameters for the dataset columns. This list can be stored as json and used to implement the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "standard_transforms = get_standard_transforms_for_dataset(train)\n",
    "\n",
    "ihs_transforms = get_ihs_transforms_for_dataset(\n",
    "    apply_transforms(train, standard_transforms), \n",
    "    drop_input=True\n",
    ")\n",
    "\n",
    "angular_transforms = [\n",
    "    get_transform('pimat_ang', 'pimat', 'angular', drop_input=True),\n",
    "    get_transform('piinv_ang', 'piinv', 'angular', drop_input=True),\n",
    "    get_transform('pien_ang', 'pien', 'angular', drop_input=True)\n",
    "]\n",
    "\n",
    "transforms = standard_transforms+ihs_transforms+angular_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': 'prode',\n",
       " 'input': 'prode',\n",
       " 'func': 'cap',\n",
       " 'params': {'cutoff': 846.3401709195086},\n",
       " 'drop_input': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': 'plant_ihs',\n",
       " 'input': 'plant',\n",
       " 'func': 'ihs',\n",
       " 'params': {'ihs_factor': 10.69928324087381},\n",
       " 'drop_input': True}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms[120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of dicts is then used by apply_transforms to apply each transformation to both the test and train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = apply_transforms(train, transforms)\n",
    "test = apply_transforms(test, transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that get_correlated_columns and get_unary_columns can be used to remove redundant and or un-informative columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correlated_column_sets = get_correlated_columns(train)\n",
    "\n",
    "for i in range(len(correlated_column_sets)):\n",
    "    test['col_set_{}'.format(i)] = test[correlated_column_sets[i][0]]\n",
    "    train['col_set_{}'.format(i)] = train[correlated_column_sets[i][0]]\n",
    "    test = test.drop(correlated_column_sets[i], axis=1)\n",
    "    train = train.drop(correlated_column_sets[i], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unary_columns = get_unary_columns(train)\n",
    "train = train.drop(unary_columns, axis=1)\n",
    "test = test.drop(unary_columns, axis=1)\n",
    "\n",
    "train['const'] = 1\n",
    "test['const'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next variable reduction procedures can be used to select the model. In this example the target is the total capex (invest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = 'invest_ihs'\n",
    "X = train.copy().drop(target, axis=1)\n",
    "y = train[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_cols = list(X)\n",
    "model = sm.OLS(train[target], train[all_cols]).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.9323008236961887\n",
      "Test R^2: 0.9295809035673137\n"
     ]
    }
   ],
   "source": [
    "print('Train R^2: {}'.format(r2_score(train[target],model.predict(train[all_cols]))))\n",
    "print('Test R^2: {}'.format(r2_score(test[target],model.predict(test[all_cols]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One selection procedure that can be used is bayesian model selection (bms in R). Note, only linear regression is supported, but for selection linear regression can be used on binary targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variables</th>\n",
       "      <th>PIP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>year</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>emp_ihs</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>pien_ang</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>piinv_ang</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tfp4_ihs</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>piship_ihs</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>plant_ihs</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>equip_ihs</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cap_ihs</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>energy_ihs</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Variables  PIP\n",
       "0         year  1.0\n",
       "16     emp_ihs  1.0\n",
       "34    pien_ang  1.0\n",
       "33   piinv_ang  1.0\n",
       "31    tfp4_ihs  1.0\n",
       "29  piship_ihs  1.0\n",
       "28   plant_ihs  1.0\n",
       "27   equip_ihs  1.0\n",
       "26     cap_ihs  1.0\n",
       "25  energy_ihs  1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bms_vars, pip, _, _ = fast_bms(X, y, iterations=10000, prior=get_binomial(25, 0.1))\n",
    "pip.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.9322376842430504\n",
      "Test R^2: 0.9295354494173846\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS(train['invest_ihs'], train[bms_vars]).fit()\n",
    "print('Train R^2: {}'.format(r2_score(train['invest_ihs'], model.predict(train[bms_vars]))))\n",
    "print('Test R^2: {}'.format(r2_score(test['invest_ihs'], model.predict(test[bms_vars]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another is selection procedure is backward_selection. Similar to fast_bms, backward_selection only supports linear regression, but produces reasonable results for binary targets. Use fast_backward_selection to use logistic regression (which uses the wald test to determine which columns to drop at each iteration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BIC</th>\n",
       "      <th>AIC</th>\n",
       "      <th>Adj. R-squared</th>\n",
       "      <th>Dropped Variables</th>\n",
       "      <th>RSS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15532.948191</td>\n",
       "      <td>15242.733042</td>\n",
       "      <td>0.932133</td>\n",
       "      <td></td>\n",
       "      <td>2413.990155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15523.309286</td>\n",
       "      <td>15240.731378</td>\n",
       "      <td>0.932137</td>\n",
       "      <td>[12]</td>\n",
       "      <td>2413.989893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15513.673796</td>\n",
       "      <td>15238.733129</td>\n",
       "      <td>0.932141</td>\n",
       "      <td>[3]</td>\n",
       "      <td>2413.990169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15504.047918</td>\n",
       "      <td>15236.744491</td>\n",
       "      <td>0.932146</td>\n",
       "      <td>[14]</td>\n",
       "      <td>2413.991959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15494.491017</td>\n",
       "      <td>15234.824831</td>\n",
       "      <td>0.932150</td>\n",
       "      <td>[15]</td>\n",
       "      <td>2414.004614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15485.029730</td>\n",
       "      <td>15233.000785</td>\n",
       "      <td>0.932154</td>\n",
       "      <td>[10]</td>\n",
       "      <td>2414.032331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15475.757325</td>\n",
       "      <td>15231.365621</td>\n",
       "      <td>0.932156</td>\n",
       "      <td>[32]</td>\n",
       "      <td>2414.089801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15466.481988</td>\n",
       "      <td>15229.727524</td>\n",
       "      <td>0.932159</td>\n",
       "      <td>[11]</td>\n",
       "      <td>2414.146811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15457.566714</td>\n",
       "      <td>15228.449492</td>\n",
       "      <td>0.932160</td>\n",
       "      <td>[1]</td>\n",
       "      <td>2414.260545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15449.630346</td>\n",
       "      <td>15228.150364</td>\n",
       "      <td>0.932157</td>\n",
       "      <td>[9]</td>\n",
       "      <td>2414.528511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            BIC           AIC  Adj. R-squared Dropped Variables          RSS\n",
       "0  15532.948191  15242.733042        0.932133                    2413.990155\n",
       "1  15523.309286  15240.731378        0.932137              [12]  2413.989893\n",
       "2  15513.673796  15238.733129        0.932141               [3]  2413.990169\n",
       "3  15504.047918  15236.744491        0.932146              [14]  2413.991959\n",
       "4  15494.491017  15234.824831        0.932150              [15]  2414.004614\n",
       "5  15485.029730  15233.000785        0.932154              [10]  2414.032331\n",
       "6  15475.757325  15231.365621        0.932156              [32]  2414.089801\n",
       "7  15466.481988  15229.727524        0.932159              [11]  2414.146811\n",
       "8  15457.566714  15228.449492        0.932160               [1]  2414.260545\n",
       "9  15449.630346  15228.150364        0.932157               [9]  2414.528511"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = backward_selection(X, y)\n",
    "bs_vars = results[0]\n",
    "results[1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.9321714258860556\n",
      "Test R^2: 0.9295290483194992\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS(train['invest_ihs'], train[bs_vars]).fit()\n",
    "print('Train R^2: {}'.format(r2_score(train['invest_ihs'],model.predict(train[bs_vars]))))\n",
    "print('Test R^2: {}'.format(r2_score(test['invest_ihs'],model.predict(test[bs_vars]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The selection functions also support group selection. A use case of this, is including square terms and requiring the selection functions to include both the original variable and square term in the model if the square term is selected.\n",
    "\n",
    "In this example, square terms are created using get_square_transforms_for_dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_r = X[bs_vars]\n",
    "square_transforms = get_square_transforms_for_dataset(X_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_r = apply_transforms(X_r, square_transforms)\n",
    "train = apply_transforms(train, square_transforms)\n",
    "test = apply_transforms(test, square_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use group selection, a group matrix needs to passed. The ij-th entry of the group matrix is 1 if variable\n",
    "j must be included with variable i and 0 otherwise. get_group_matrix can be used to create the group matrix, using the dataset and a group_dict where the values are lists of variables that must be included in the model if the corresponding key is in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'year_sqr': ['year'],\n",
       " 'dtfp4_sqr': ['dtfp4'],\n",
       " 'emp_ihs_sqr': ['emp_ihs'],\n",
       " 'pay_ihs_sqr': ['pay_ihs'],\n",
       " 'prode_ihs_sqr': ['prode_ihs'],\n",
       " 'prodh_ihs_sqr': ['prodh_ihs'],\n",
       " 'prodw_ihs_sqr': ['prodw_ihs'],\n",
       " 'vship_ihs_sqr': ['vship_ihs'],\n",
       " 'matcost_ihs_sqr': ['matcost_ihs'],\n",
       " 'vadd_ihs_sqr': ['vadd_ihs'],\n",
       " 'energy_ihs_sqr': ['energy_ihs'],\n",
       " 'cap_ihs_sqr': ['cap_ihs'],\n",
       " 'equip_ihs_sqr': ['equip_ihs'],\n",
       " 'plant_ihs_sqr': ['plant_ihs'],\n",
       " 'piship_ihs_sqr': ['piship_ihs'],\n",
       " 'tfp5_ihs_sqr': ['tfp5_ihs'],\n",
       " 'tfp4_ihs_sqr': ['tfp4_ihs'],\n",
       " 'piinv_ang_sqr': ['piinv_ang'],\n",
       " 'pien_ang_sqr': ['pien_ang']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_dict = get_group_dict(square_transforms)\n",
    "group_matrix = get_group_matrix(X_r, group_dict)\n",
    "\n",
    "group_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = backward_selection(X_r, y, group_matrix=group_matrix)\n",
    "bs_vars_w_sqr = result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.9340769916055198\n",
      "Test R^2: 0.931257287398192\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS(train['invest_ihs'], train[bs_vars_w_sqr]).fit()\n",
    "print('Train R^2: {}'.format(r2_score(train['invest_ihs'],model.predict(train[bs_vars_w_sqr]))))\n",
    "print('Test R^2: {}'.format(r2_score(test['invest_ihs'],model.predict(test[bs_vars_w_sqr]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another use of group selection is using b-splines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_r = X[bs_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bspline_transforms = get_bspline_transforms_for_dataset(X_r, df=3, degree=2)\n",
    "X_r = apply_transforms(X_r, bspline_transforms)\n",
    "train = apply_transforms(train, bspline_transforms)\n",
    "test = apply_transforms(test, bspline_transforms)\n",
    "\n",
    "group_matrix = get_group_matrix(X_r, get_group_dict(bspline_transforms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = backward_selection(X_r, y, group_matrix=group_matrix)\n",
    "bs_vars_w_spline = t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.9349460070644586\n",
      "Test R^2: 0.9320557617838351\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS(train['invest_ihs'], train[bs_vars_w_spline]).fit()\n",
    "print('Train R^2: {}'.format(r2_score(train['invest_ihs'],model.predict(train[bs_vars_w_spline]))))\n",
    "print('Test R^2: {}'.format(r2_score(test['invest_ihs'],model.predict(test[bs_vars_w_spline]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Using fast_backward_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, an artificial dataset is used to demonstrate the use of fast_backward_selection, which supports regression using any statsmodel object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y, coeff = sklearn.datasets.make_regression(100000, 100, 20,  noise=500, coef=True)\n",
    "y = 1*(1/(1+np.exp(-(y-3*y.std())/y.std()))>np.random.rand(100000))\n",
    "\n",
    "grp = np.eye(100)\n",
    "grp[:, 99] = 1\n",
    "grp[:, 98] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fbw_result = fast_backward_selection(\n",
    "    pd.DataFrame(X), \n",
    "    pd.Series(y),\n",
    "    sm.GLM,model_kwargs={'family':sm.families.Binomial()},\n",
    "    criteria='bic',\n",
    "    refit_freq=2, \n",
    "    group_matrix=grp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dropped Variables</th>\n",
       "      <th>BIC</th>\n",
       "      <th>AIC</th>\n",
       "      <th>Max p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>-77468.790776</td>\n",
       "      <td>13913.578906</td>\n",
       "      <td>0.163514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[3, 61]</td>\n",
       "      <td>-77487.208838</td>\n",
       "      <td>13909.581525</td>\n",
       "      <td>0.163610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[36, 29]</td>\n",
       "      <td>-77505.628207</td>\n",
       "      <td>13905.582837</td>\n",
       "      <td>0.163342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[93, 94]</td>\n",
       "      <td>-77524.037232</td>\n",
       "      <td>13901.594493</td>\n",
       "      <td>0.163606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[58, 84]</td>\n",
       "      <td>-77542.452571</td>\n",
       "      <td>13897.599834</td>\n",
       "      <td>0.163101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[72, 53]</td>\n",
       "      <td>-77560.837313</td>\n",
       "      <td>13893.635773</td>\n",
       "      <td>0.163690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[56, 89]</td>\n",
       "      <td>-77579.224955</td>\n",
       "      <td>13889.668812</td>\n",
       "      <td>0.163570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[59, 13]</td>\n",
       "      <td>-77597.599887</td>\n",
       "      <td>13885.714560</td>\n",
       "      <td>0.164072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0, 75]</td>\n",
       "      <td>-77615.976477</td>\n",
       "      <td>13881.758652</td>\n",
       "      <td>0.163748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[88, 50]</td>\n",
       "      <td>-77634.340598</td>\n",
       "      <td>13877.815211</td>\n",
       "      <td>0.163400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dropped Variables           BIC           AIC  Max p-value\n",
       "0                [] -77468.790776  13913.578906     0.163514\n",
       "1           [3, 61] -77487.208838  13909.581525     0.163610\n",
       "2          [36, 29] -77505.628207  13905.582837     0.163342\n",
       "3          [93, 94] -77524.037232  13901.594493     0.163606\n",
       "4          [58, 84] -77542.452571  13897.599834     0.163101\n",
       "5          [72, 53] -77560.837313  13893.635773     0.163690\n",
       "6          [56, 89] -77579.224955  13889.668812     0.163570\n",
       "7          [59, 13] -77597.599887  13885.714560     0.164072\n",
       "8           [0, 75] -77615.976477  13881.758652     0.163748\n",
       "9          [88, 50] -77634.340598  13877.815211     0.163400"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbw_result[1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
